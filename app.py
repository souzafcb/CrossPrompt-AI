import streamlit as st
from langchain_ollama import ChatOllama
from langchain.prompts import PromptTemplate
from langchain.retrievers.web_research import WebResearchRetriever
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.schema.runnable import RunnableLambda
import json
import os

st.set_page_config(layout="wide")
st.title("üîó Cross-Prompt IA com Mem√≥ria e Enriquecimento Web")

# Modelos locais via Ollama
llm_1 = ChatOllama(model="mistral", temperature=0.4)
llm_2 = ChatOllama(model="llama3", temperature=0.5)
llm_3 = ChatOllama(model="phi3", temperature=0.3)

# Vetorizador RAG
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vectorstore = FAISS.load_local("rag_index", embeddings=embedding_model) if os.path.exists("rag_index") else FAISS.from_texts([""], embedding_model)

# Web Retriever
def retrieve_web_context(query: str):
    retriever = WebResearchRetriever.from_llm_and_tools(
        llm=llm_1,
        search_sources=["duckduckgo"],
        vectorstore=vectorstore,
        k=3
    )
    documents = retriever.invoke({"question": query})
    return "\n".join([doc.page_content for doc in documents])

# PROMPTS
prompt_template_1 = PromptTemplate.from_template("""
Voc√™ √© um assistente especializado em an√°lise de tarefas complexas. [...]""")
chain_1 = prompt_template_1 | llm_1

prompt_template_2 = PromptTemplate.from_template("""
Com base na an√°lise t√©cnica a seguir [...]""")
chain_2 = prompt_template_2 | llm_2

prompt_template_3 = PromptTemplate.from_template("""
A seguir est√° um plano de a√ß√£o t√©cnico [...]""")
chain_3 = prompt_template_3 | llm_3

# Interface Streamlit
st.sidebar.header("Entrada")
tarefa = st.sidebar.text_area("Descreva a tarefa:", value="Desenvolver um sistema de orquestra√ß√£o e enriquecimento de prompt para LLMs com foco em uso laboratorial e automa√ß√£o anal√≠tica.")
executar = st.sidebar.button("Executar an√°lise completa")
etapa_selecionada = st.sidebar.radio("Executar etapa espec√≠fica:", ["Nenhuma", "Resumo T√©cnico", "Plano de A√ß√£o", "Avalia√ß√£o Cr√≠tica"])
exportar = st.sidebar.button("Exportar Resultado em Markdown")

# Carregar mem√≥ria
if os.path.exists("memoria_crossprompt.json"):
    with open("memoria_crossprompt.json", "r", encoding="utf-8") as f:
        memoria = json.load(f)
else:
    memoria = {}

st.sidebar.markdown("---")
st.sidebar.write("üß† Mem√≥ria atual:")
with st.sidebar.expander("Visualizar mem√≥ria", expanded=False):
    for chave, valor in memoria.items():
        st.markdown(f"**{chave.upper()}**\n\n{valor[:500]}{'...' if len(valor) > 500 else ''}")

context = {"tarefa": tarefa}
web_context = ""
resumo = plano = avaliacao = ""

if executar or etapa_selecionada != "Nenhuma":
    with st.spinner("üîç Buscando contexto na web..."):
        web_context = retrieve_web_context(tarefa)

if executar or etapa_selecionada == "Resumo T√©cnico":
    with st.spinner("‚úèÔ∏è Gerando resumo t√©cnico..."):
        resumo = chain_1.invoke({"tarefa": tarefa, "memoria": json.dumps(memoria), "web_context": web_context}).content
        st.subheader("Resumo T√©cnico")
        st.markdown(resumo)
        context["resumo"] = resumo

if executar or etapa_selecionada == "Plano de A√ß√£o":
    if not resumo:
        resumo = memoria.get("resumo", "")
    with st.spinner("üìò Elaborando plano de a√ß√£o..."):
        plano = chain_2.invoke({"resumo": resumo, "memoria": json.dumps(memoria), "web_context": web_context}).content
        st.subheader("Plano de A√ß√£o")
        st.markdown(plano)
        context["plano"] = plano

if executar or etapa_selecionada == "Avalia√ß√£o Cr√≠tica":
    if not plano:
        plano = memoria.get("plano", "")
    with st.spinner("üîé Realizando avalia√ß√£o cr√≠tica..."):
        avaliacao = chain_3.invoke({"plano": plano, "memoria": json.dumps(memoria), "web_context": web_context}).content
        st.subheader("Avalia√ß√£o Cr√≠tica")
        st.markdown(avaliacao)
        context["avaliacao"] = avaliacao

# Atualiza mem√≥ria
if executar:
    memoria.update({"tarefa": tarefa, "web_context": web_context, "resumo": resumo, "plano": plano, "avaliacao": avaliacao})
    with open("memoria_crossprompt.json", "w", encoding="utf-8") as f:
        json.dump(memoria, f, ensure_ascii=False, indent=4)
    st.sidebar.success("üß† Mem√≥ria atualizada com sucesso!")

# Exportar em markdown
if exportar:
    with open("resultado_crossprompt.md", "w", encoding="utf-8") as f:
        f.write(f"# Tarefa\n{tarefa}\n\n")
        if "resumo" in context:
            f.write(f"## Resumo T√©cnico\n{context['resumo']}\n\n")
        if "plano" in context:
            f.write(f"## Plano de A√ß√£o\n{context['plano']}\n\n")
        if "avaliacao" in context:
            f.write(f"## Avalia√ß√£o Cr√≠tica\n{context['avaliacao']}\n\n")
    st.success("‚úÖ Resultado exportado como 'resultado_crossprompt.md'")
<substituiremos com o conte√∫do do canvas em pr√≥xima c√©lula>
